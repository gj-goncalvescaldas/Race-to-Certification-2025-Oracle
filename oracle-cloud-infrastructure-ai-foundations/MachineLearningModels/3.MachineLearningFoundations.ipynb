{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbb8b3fc-6a86-49cb-9910-15aef7f7de0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e2536df-44c2-4fd2-96d1-7b80e362085f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"column_2C_weka.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b583c7e-9a94-4b7b-9ac7-2ce45916eecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed0260d5-bb5b-4a2a-97bf-530a16f2705e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78bbd47-3807-4ac7-a6f4-09019a522b67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ed0e0eb-1478-4a46-b4e5-8bee2530f0a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4062e867-dc05-4a50-9a52-d7c638d6fe7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "color_list = ['red' if i == 'Abnormal' else 'green' for i in data.loc[:, 'class']]\n",
    "\n",
    "pd.plotting.scatter_matrix(data.loc[:, data.columns != 'class'],\n",
    "                           c=color_list,\n",
    "                           figsize=[10,10],\n",
    "                           diagonal='hist',\n",
    "                           alpha=0.5,\n",
    "                           s=200,\n",
    "                           marker = '*',\n",
    "                           edgecolor = \"black\"\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc50b660-79ea-4159-8b67-7c2e54007d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Similar to Demo: Basic Machine Learning Part ‚Äì 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6469632-1ea5-488a-a33e-06fbc7b80ac8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x = data.loc[:, data.columns!='class']\n",
    "y = data.loc[:, 'class']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)\n",
    "log_reg.predict(x_test)\n",
    "log_reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ceea147b-fc5e-4254-813c-f7f9726cb0ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Similar to Demo: Basic Machine Learning Part ‚Äì 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0eb6cdd-c1a2-4e8e-82ed-588f7cb20e06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x = data.loc[:, data.columns!='class']\n",
    "y = data.loc[:, 'class']\n",
    "\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)\n",
    "log_reg.predict(x_test)\n",
    "log_reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36a06920-1f9c-47ea-9426-1516c1bd9d3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìå What is the K-Nearest Neighbor (KNN) Algorithm?\n",
    "\n",
    "üé• **Video Title:** What is the K-Nearest Neighbor (KNN) Algorithm?  \n",
    "üë®‚Äçüè´ **Creator:** [IBM Technology](https://www.youtube.com/@IBMTechnology)  \n",
    "üîó **Watch here:** [YouTube Video](https://www.youtube.com/watch?v=b6uHw7QW_n4)  \n",
    "üñºÔ∏è **Thumbnail:**  \n",
    "![KNN](https://i.ytimg.com/vi/b6uHw7QW_n4/hqdefault.jpg)\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ KNN in a Nutshell\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a **supervised learning algorithm** used for both **classification and regression**, based on the concept of **similarity proximity**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Key Concepts Explained\n",
    "\n",
    "### üìå 1. Core Principle\n",
    "- KNN classifies data based on how its **features compare to its \"K\" nearest neighbors**.\n",
    "- It assumes that similar things exist near each other.\n",
    "\n",
    "### üçè 2. Fruit Example\n",
    "- Features: **Sweetness (x-axis)** & **Crunchiness (y-axis)**.\n",
    "- New data points are classified by checking proximity to existing labeled data (e.g., apples vs oranges).\n",
    "\n",
    "### üßÆ 3. Distance Metrics\n",
    "- Measures proximity using:\n",
    "  - **Euclidean Distance**\n",
    "  - **Manhattan Distance**\n",
    "- Visualization: **Voronoi Diagrams** are used to show decision boundaries.\n",
    "\n",
    "### üî¢ 4. Choosing the Right ‚ÄòK‚Äô\n",
    "- **K = 1**: Assign class of nearest neighbor.\n",
    "- Larger K values smooth the model‚Äôs decisions.\n",
    "- Use **odd K values** to avoid classification ties.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Pros & Cons of KNN\n",
    "\n",
    "### ‚úÖ Strengths\n",
    "- ‚úÖ Simple and intuitive\n",
    "- ‚úÖ Few hyperparameters (just K & distance metric)\n",
    "- ‚úÖ Learns in real-time as new data is added\n",
    "\n",
    "### ‚ùå Weaknesses\n",
    "- ‚ùå Poor scalability with large datasets (lazy learning = memory-intensive)\n",
    "- ‚ùå Suffers from the **curse of dimensionality**\n",
    "- ‚ùå High sensitivity to noisy or irrelevant features\n",
    "\n",
    "---\n",
    "## üîç Exploring the Impact of K: Overfitting vs. Underfitting\n",
    "\n",
    "Choosing the right value of **K** in the K-Nearest Neighbor algorithm is crucial ‚Äî it directly impacts the model‚Äôs **bias-variance tradeoff** and overall performance.\n",
    "\n",
    "---\n",
    "\n",
    "### üî¢ What Does ‚ÄòK‚Äô Really Mean?\n",
    "\n",
    "- The **K** in KNN refers to the number of nearest data points used to determine a prediction for a new instance.\n",
    "- You can think of it as \"how many friends you're asking for advice\" before deciding.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Low K Value = High Variance (Overfitting)\n",
    "\n",
    "- Example: **K = 1**\n",
    "  - The model simply chooses the **closest neighbor**.\n",
    "  - This can lead to **overfitting** because it's overly sensitive to noise or outliers.\n",
    "  - Every tiny fluctuation in the dataset affects predictions.\n",
    "  \n",
    "üìâ **Overfitting Symptoms:**\n",
    "- Excellent training accuracy, but poor generalization to new data.\n",
    "- Highly irregular decision boundaries.\n",
    "\n",
    "---\n",
    "\n",
    "### üìâ High K Value = High Bias (Underfitting)\n",
    "\n",
    "- Example: **K = 15 or 20**\n",
    "  - The model averages over many neighbors, potentially from different classes.\n",
    "  - Can lead to **underfitting**, as it smooths out local patterns.\n",
    "  \n",
    "üìâ **Underfitting Symptoms:**\n",
    "- Model is too simplistic to capture complex patterns.\n",
    "- Poor training **and** test performance.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ How to Choose the Best K?\n",
    "\n",
    "‚úÖ **Best Practices:**\n",
    "- Use **cross-validation** to test different K values and find the sweet spot.\n",
    "- Choose an **odd value** of K to avoid tie votes in binary classification.\n",
    "- Try plotting an **error rate vs. K** graph ‚Äî this can help visualize where underfitting and overfitting happen.\n",
    "\n",
    "üõ†Ô∏è **Typical Range:**  \n",
    "- Start testing with K values in the range **3‚Äì15**.\n",
    "- Use **grid search** or other hyperparameter tuning tools for optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Bonus Tips\n",
    "\n",
    "- **Data Scaling Matters:** Always scale features (e.g., with StandardScaler) before applying KNN, or else distance-based metrics become unreliable.\n",
    "- **Dimensionality:** Too many features can dilute distance comparisons (curse of dimensionality), making the choice of K even harder.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## üè• Real-World Applications\n",
    "\n",
    "- üß¨ **Healthcare:** Predicting disease risk (e.g., heart attacks, prostate cancer)\n",
    "- üí∏ **Finance:** Stock prediction, fraud detection\n",
    "- üõ†Ô∏è **Missing Data Imputation:** Estimating unknown values\n",
    "- üì∫ **Recommendation Systems:** Suggesting products, movies, etc.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3af7522b-5c9f-4a0c-a945-42d5525279e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classification using KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b8ba5cb-7639-463d-bde8-dace56c7e4d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x = data.loc[:, data.columns!='class']\n",
    "y = data.loc[:, 'class']\n",
    "\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "neig = np.arange(1, 25)\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for i, k in enumerate(neig):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    train_accuracy.append(knn.score(x_train, y_train))\n",
    "\n",
    "    test_accuracy.append(knn.score(x_test, y_test))\n",
    "\n",
    "plt.figure(figsize=[13,8])\n",
    "plt.plot(neig, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neig, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.title('k value VS Accuracy')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(neig)\n",
    "plt.savefig('graph.png')\n",
    "plt.show()\n",
    "print(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy), 1+test_accuracy.index(np.max(test_accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0bb21e5-2a38-4ddb-9d44-ebbbe1e549c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "weather"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.MachineLearningFoundations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
