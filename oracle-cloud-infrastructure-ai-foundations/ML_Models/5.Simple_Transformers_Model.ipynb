{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94aaedb1-c2a5-4817-8a41-881796c64477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (1.26.3)\nRequirement already satisfied: sentence-transformers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (5.0.0)\nRequirement already satisfied: faiss-cpu in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (1.11.0)\nRequirement already satisfied: transformers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (4.53.2)\nRequirement already satisfied: accelerate in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (1.8.1)\nRequirement already satisfied: sentencepiece in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (0.2.0)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from sentence-transformers) (2.7.1)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from sentence-transformers) (0.33.4)\nRequirement already satisfied: Pillow in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from sentence-transformers) (4.14.1)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.11/site-packages (from faiss-cpu) (23.2)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from transformers) (3.13.4)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.11/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from transformers) (0.5.3)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.11/site-packages (from accelerate) (5.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\nRequirement already satisfied: sympy>=1.13.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\nRequirement already satisfied: networkx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9146a5c7-1112-40e3-9516-e60ebb46643a/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade PyMuPDF sentence-transformers faiss-cpu transformers accelerate sentencepiece \n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d65d354e-8142-4d5e-b099-9c1968e60857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CV with 980 words.\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Load \n",
    "import fitz  \n",
    "\n",
    "def load_pdf(path):\n",
    "    doc = fitz.open(path)\n",
    "    return \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "cv_text = load_pdf(\"Data/CV_GustavoCaldas.pdf\")\n",
    "print(f\"Loaded CV with {len(cv_text.split())} words.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "502b7523-133e-4adf-a966-f83f267efa89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 7 chunks.\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Split into chunks for embedding (150 words each)\n",
    "def split_into_chunks(text, max_words=150):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_words):\n",
    "        chunk = \" \".join(words[i:i+max_words])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "chunks = split_into_chunks(cv_text)\n",
    "print(f\"Split into {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54c62605-b866-4011-96eb-5b4cd52ce3f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00344299680444c89e2220b8e6982a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c6dcfc87aa48bf9152c9c6f0eb7fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61892841ce4e443cb771cff04f60f02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521ea737a4f647c4ba14162e89048a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6bc62ae95241d38a8687ecf57a1c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36344501ff6475787683eeea7537ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e528f510d541529b6f001182595d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc49c9bbb7ea4e5ab04357a51dae6b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46ff8dd2a1c468a93b7849b5ab8038b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b63aa99192f481db8778962f3df5068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd0db5796e247adaeb5ac954d287250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings created.\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Generate embeddings with sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embed_model.encode(chunks)\n",
    "print(\"Embeddings created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5efa3e48-4db2-4bab-ad0f-bf1fa8284c81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index created with 7 vectors.\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Build FAISS index for similarity search\n",
    "import faiss\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.array(embeddings).astype('float32'))\n",
    "print(f\"FAISS index created with {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32dac346-43ad-4de9-be0d-de588fcc3910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78dcbd0f6744ad190a7b69afbc67307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d62636e55804bb0b99de60958d974b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfec14fd3812493c866d8b302b9a75f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbf85b5bace4e4eb0df9cb8bf9e7c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae913cf23f84b829ad569639385dfb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d178a85e5df49389d6d63501be3163d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f3b9a747fd420db3d977ecd30c386f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model: google/flan-t5-small\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Load lightweight LLM (flan-t5-small)\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "model.eval()\n",
    "print(f\"Loaded model: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85e1e416-5c26-4188-ab65-b9f8b3fa86f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STEP 6: Define question-answer function\n",
    "def ask_question(question, top_k=3, max_new_tokens=150):\n",
    "    # Embed question\n",
    "    q_embed = embed_model.encode([question])\n",
    "    \n",
    "    \n",
    "    D, I = index.search(np.array(q_embed).astype('float32'), top_k)\n",
    "    context = \"\\n\".join([chunks[i] for i in I[0]])\n",
    "    \n",
    "   \n",
    "    prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20c7793c-9b11-4a7c-a458-08644d645542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n DATA ENGINEER NATIONALE-NEDERLANDEN\n"
     ]
    }
   ],
   "source": [
    "response = ask_question(\"What experience does Gustavo have with Databricks?\")\n",
    "print(\"Answer:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aaf03f3-8681-4b87-a296-e09afb2d43fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n he desarrollado un fuerte interés por el mundo de los datos, orientando mi aprendizaje y experiencia hacia la Ingeniera de Datos, el Machine Learning y la Visualización. I apasiona construir bases de datos sólidas, disear modelos de predicción y extraer information valiosa que aporte un impacto significativo a las empresas. Mis principales intereses giran en torno a transform\n"
     ]
    }
   ],
   "source": [
    "response = ask_question(\"Which are Gustavo's strengths?\")\n",
    "print(\"Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3abe5d2-70b6-437f-8249-cf4d41abc007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n educaciain y formacin 19/06/2023 – 11/12/2023 Madrid, Espaa BOOTCAMP EN MARKETING DATA ANALYTICS Universidad Internacional de La Rioja Web www.unir.net Nivel en el MEC Nivel 5 EQF-MEC Lengua(s) materna(s): PORTUGUÉS Otro(s) idioma(s): COMPRENSIN EXPRESIN ORAL EXPRESIN ESCRITA Comprensión auditiva Comp\n"
     ]
    }
   ],
   "source": [
    "response = ask_question(\"EXPERIENCIA LABORAL\")\n",
    "print(\"Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b81b98f-8897-4c8b-ba44-d7c26b444d03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n Universidad Internacional de La Rioja Web www.unir.net Nivel en el MEC Nivel 5 EQF-MEC Lengua(s) materna(s): PORTUGUÉS Otro(s) idioma(s): COMPRENSIN EXPRESSIN ORAL EXPRESSIN ESCRITA Comprensión auditiva Comprensión lectora Producción oral\n"
     ]
    }
   ],
   "source": [
    "response = ask_question(\" Universidade do Minho\")\n",
    "print(\"Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08726b01-8bdd-4a0b-ac49-06934b7e2ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Disclaimer\n",
    "\n",
    "Due to computational resource constraints in my cloud environment (Databricks Free), this assistant uses a lightweight language model (`flan-t5-small`) that balances speed and accessibility but sacrifices some accuracy and detail in responses. For best performance, a larger, more powerful model would be required, which typically needs GPU resources and paid API access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9c782dc-4747-4d51-8b4e-a1a654c6baac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.Simple_Transformers_Model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
